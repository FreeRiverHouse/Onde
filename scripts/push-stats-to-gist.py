#!/usr/bin/env python3
"""
Push trading stats to GitHub Gist for static site consumption.

Creates/updates a public gist with trading stats JSON that the static site
can fetch at runtime, bypassing the static export limitation.

Usage:
    python push-stats-to-gist.py [--create] [--source v1|v2|all]

Options:
    --create        Create a new gist (first run only)
    --source X      Data source: v1, v2, or all (combined). Default: v2
"""

import json
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path

# Paths
SCRIPT_DIR = Path(__file__).parent
TRADES_FILE_V1 = SCRIPT_DIR / "kalshi-trades.jsonl"
TRADES_FILE_V2 = SCRIPT_DIR / "kalshi-trades-v2.jsonl"
SETTLEMENTS_FILE_V1 = SCRIPT_DIR / "kalshi-settlements.json"  # T349
SETTLEMENTS_FILE_V2 = SCRIPT_DIR / "kalshi-settlements-v2.json"  # T349
GIST_ID_FILE = SCRIPT_DIR.parent / "data" / "trading" / "stats-gist-id.txt"
VOLATILITY_FILE = SCRIPT_DIR.parent / "data" / "ohlc" / "volatility-stats.json"
HEALTH_STATUS_FILE = SCRIPT_DIR.parent / "data" / "trading" / "autotrader-health.json"  # T472
API_LATENCY_FILE = SCRIPT_DIR / "kalshi-latency-profile.json"  # T398
STATS_FILENAME = "onde-trading-stats.json"

def load_volatility_stats():
    """Load volatility stats from OHLC analysis."""
    if not VOLATILITY_FILE.exists():
        return None
    
    try:
        with open(VOLATILITY_FILE, 'r') as f:
            data = json.load(f)
        
        # Extract compact summary for each asset
        vol_summary = {
            "generated_at": data.get("generated_at"),
            "assets": {}
        }
        
        for asset, asset_data in data.get("assets", {}).items():
            periods = asset_data.get("periods", {})
            model_assumption = asset_data.get("model_assumption_hourly", 0) * 100
            
            # Get 7d, 14d, 30d volatility
            vol_summary["assets"][asset] = {
                "modelAssumption": round(model_assumption, 2),
                "periods": {}
            }
            
            for period in ["7d", "14d", "30d"]:
                if period in periods and "vol_hourly" not in periods[period].get("error", ""):
                    p = periods[period]
                    vol_summary["assets"][asset]["periods"][period] = {
                        "realized": round(p.get("vol_hourly", 0), 2),
                        "deviation": round(p.get("deviation_from_model_pct", 0), 1),
                        "priceRangePct": round(p.get("price_range_pct", 0), 2)
                    }
        
        return vol_summary
    except Exception as e:
        print(f"Warning: Could not load volatility stats: {e}")
        return None


def load_api_latency_stats():
    """Load API latency profile stats (T398).
    
    Reads the latency profile generated by the autotrader and creates
    a summary suitable for dashboard display.
    """
    if not API_LATENCY_FILE.exists():
        return None
    
    try:
        with open(API_LATENCY_FILE, 'r') as f:
            profile = json.load(f)
        
        endpoints = profile.get("endpoints", {})
        if not endpoints:
            return None
        
        # Categorize endpoints
        categories = {
            "kalshi": {"endpoints": [], "total_calls": 0, "latencies": []},
            "binance": {"endpoints": [], "total_calls": 0, "latencies": []},
            "coingecko": {"endpoints": [], "total_calls": 0, "latencies": []},
            "coinbase": {"endpoints": [], "total_calls": 0, "latencies": []},
            "other": {"endpoints": [], "total_calls": 0, "latencies": []}
        }
        
        for endpoint, stats in endpoints.items():
            count = stats.get("count", 0)
            if count == 0:
                continue
            
            avg_ms = stats.get("avg_ms", 0)
            
            # Categorize by endpoint name
            if "kalshi" in endpoint.lower():
                cat = "kalshi"
            elif "binance" in endpoint.lower():
                cat = "binance"
            elif "coingecko" in endpoint.lower() or "gecko" in endpoint.lower():
                cat = "coingecko"
            elif "coinbase" in endpoint.lower():
                cat = "coinbase"
            else:
                cat = "other"
            
            categories[cat]["endpoints"].append({
                "name": endpoint,
                "count": count,
                "avgMs": round(avg_ms, 1),
                "p95Ms": round(stats.get("p95_ms", avg_ms), 1),
                "maxMs": round(stats.get("max_ms", avg_ms), 1)
            })
            categories[cat]["total_calls"] += count
            categories[cat]["latencies"].append(avg_ms)
        
        # Calculate category summaries
        summary = {
            "generated_at": profile.get("generated_at", datetime.now(timezone.utc).isoformat()),
            "categories": {},
            "slowest": [],
            "overall": {
                "total_calls": 0,
                "avg_latency_ms": 0
            }
        }
        
        all_latencies = []
        for cat_name, cat_data in categories.items():
            if cat_data["total_calls"] > 0:
                cat_avg = sum(cat_data["latencies"]) / len(cat_data["latencies"])
                summary["categories"][cat_name] = {
                    "total_calls": cat_data["total_calls"],
                    "endpoint_count": len(cat_data["endpoints"]),
                    "avg_latency_ms": round(cat_avg, 1),
                    "endpoints": sorted(cat_data["endpoints"], key=lambda x: -x["avgMs"])[:5]  # Top 5 slowest
                }
                summary["overall"]["total_calls"] += cat_data["total_calls"]
                all_latencies.extend(cat_data["latencies"])
        
        if all_latencies:
            summary["overall"]["avg_latency_ms"] = round(sum(all_latencies) / len(all_latencies), 1)
        
        # Get top 5 slowest endpoints overall
        all_endpoints = []
        for cat_data in categories.values():
            all_endpoints.extend(cat_data["endpoints"])
        summary["slowest"] = sorted(all_endpoints, key=lambda x: -x["avgMs"])[:5]
        
        return summary
    except Exception as e:
        print(f"Warning: Could not load API latency stats: {e}")
        return None


def load_settlements_stats():
    """Load settlement statistics from v1 and v2 files (T349).
    
    Returns combined settlement stats for dashboard display.
    """
    def process_settlements_file(filepath):
        """Process a single settlements file."""
        if not filepath.exists():
            return {
                "totalSettled": 0,
                "totalPending": 0,
                "totalWon": 0,
                "totalLost": 0,
                "winRate": 0,
                "totalPnlCents": 0,
                "totalPayoutCents": 0,
                "byAsset": {
                    "BTC": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0},
                    "ETH": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0}
                },
                "lastSettlementTime": None,
                "oldestPendingTime": None
            }
        
        try:
            with open(filepath, 'r') as f:
                data = json.load(f)
            
            trades = data.get("trades", {})
            
            settled = [t for t in trades.values() if t.get("status") == "settled"]
            pending = [t for t in trades.values() if t.get("status") != "settled"]
            
            won = [t for t in settled if t.get("won", False)]
            lost = [t for t in settled if not t.get("won", False)]
            
            total_pnl = sum(t.get("pnl_cents", 0) for t in settled)
            total_payout = sum(t.get("payout_cents", 0) for t in settled)
            
            # By asset breakdown
            by_asset = {
                "BTC": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0},
                "ETH": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0}
            }
            
            for ticker, t in trades.items():
                asset = "ETH" if "KXETHD" in ticker else "BTC"
                if t.get("status") == "settled":
                    by_asset[asset]["settled"] += 1
                    by_asset[asset]["pnlCents"] += t.get("pnl_cents", 0)
                    if t.get("won"):
                        by_asset[asset]["won"] += 1
                    else:
                        by_asset[asset]["lost"] += 1
                else:
                    by_asset[asset]["pending"] += 1
            
            # Settlement times
            settlement_times = [t.get("expiry_time") for t in settled if t.get("expiry_time")]
            pending_times = [t.get("expiry_time") for t in pending if t.get("expiry_time")]
            
            return {
                "totalSettled": len(settled),
                "totalPending": len(pending),
                "totalWon": len(won),
                "totalLost": len(lost),
                "winRate": round(len(won) / len(settled) * 100, 1) if settled else 0,
                "totalPnlCents": total_pnl,
                "totalPayoutCents": total_payout,
                "byAsset": by_asset,
                "lastSettlementTime": max(settlement_times) if settlement_times else None,
                "oldestPendingTime": min(pending_times) if pending_times else None
            }
        except Exception as e:
            print(f"Warning: Could not load settlements from {filepath}: {e}")
            return None
    
    v1_stats = process_settlements_file(SETTLEMENTS_FILE_V1)
    v2_stats = process_settlements_file(SETTLEMENTS_FILE_V2)
    
    # Combine stats
    def combine_stats(a, b):
        if a is None and b is None:
            return None
        a = a or {"totalSettled": 0, "totalPending": 0, "totalWon": 0, "totalLost": 0, 
                  "totalPnlCents": 0, "totalPayoutCents": 0, "byAsset": {
                      "BTC": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0},
                      "ETH": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0}
                  }}
        b = b or {"totalSettled": 0, "totalPending": 0, "totalWon": 0, "totalLost": 0,
                  "totalPnlCents": 0, "totalPayoutCents": 0, "byAsset": {
                      "BTC": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0},
                      "ETH": {"settled": 0, "won": 0, "lost": 0, "pending": 0, "pnlCents": 0}
                  }}
        
        combined = {
            "totalSettled": a["totalSettled"] + b["totalSettled"],
            "totalPending": a["totalPending"] + b["totalPending"],
            "totalWon": a["totalWon"] + b["totalWon"],
            "totalLost": a["totalLost"] + b["totalLost"],
            "totalPnlCents": a["totalPnlCents"] + b["totalPnlCents"],
            "totalPayoutCents": a["totalPayoutCents"] + b["totalPayoutCents"],
            "byAsset": {}
        }
        
        combined["winRate"] = round(combined["totalWon"] / combined["totalSettled"] * 100, 1) if combined["totalSettled"] > 0 else 0
        
        for asset in ["BTC", "ETH"]:
            combined["byAsset"][asset] = {
                "settled": a["byAsset"][asset]["settled"] + b["byAsset"][asset]["settled"],
                "won": a["byAsset"][asset]["won"] + b["byAsset"][asset]["won"],
                "lost": a["byAsset"][asset]["lost"] + b["byAsset"][asset]["lost"],
                "pending": a["byAsset"][asset]["pending"] + b["byAsset"][asset]["pending"],
                "pnlCents": a["byAsset"][asset]["pnlCents"] + b["byAsset"][asset]["pnlCents"]
            }
        
        # Use most recent settlement time
        times = [x for x in [a.get("lastSettlementTime"), b.get("lastSettlementTime")] if x]
        combined["lastSettlementTime"] = max(times) if times else None
        
        # Use oldest pending time
        pending_times = [x for x in [a.get("oldestPendingTime"), b.get("oldestPendingTime")] if x]
        combined["oldestPendingTime"] = min(pending_times) if pending_times else None
        
        return combined
    
    combined = combine_stats(v1_stats, v2_stats)
    
    return {
        "v1": v1_stats,
        "v2": v2_stats,
        "combined": combined
    }


def load_health_status():
    """Load autotrader health status (T620).
    
    Supports both formats:
    - T472 format (from autotrader internal): is_running, last_cycle_time, etc.
    - T488 format (from external script): process.running, status, issues, etc.
    """
    if not HEALTH_STATUS_FILE.exists():
        return None
    
    try:
        with open(HEALTH_STATUS_FILE, 'r') as f:
            data = json.load(f)
        
        # Detect format by checking for T472 field (is_running) vs T488 field (process)
        if "is_running" in data:
            # T472 format (autotrader internal - preferred)
            return {
                "is_running": data.get("is_running", False),
                "last_cycle_time": data.get("last_cycle_time"),
                "cycle_count": data.get("cycle_count", 0),
                "dry_run": data.get("dry_run", False),
                "trades_today": data.get("trades_today", 0),
                "today_won": data.get("today_won", 0),
                "today_lost": data.get("today_lost", 0),
                "today_pending": data.get("today_pending", 0),
                "win_rate_today": data.get("win_rate_today", 0),
                "pnl_today_cents": data.get("pnl_today_cents", 0),
                "circuit_breaker_active": data.get("circuit_breaker_active", False),
                "consecutive_losses": data.get("consecutive_losses", 0),
                "status": data.get("status", "unknown"),
                "format": "t472"
            }
        elif "process" in data:
            # T488 format (external script - backward compat)
            process = data.get("process", {})
            trades = data.get("trades", {})
            log = data.get("log", {})
            return {
                "is_running": process.get("running", False),
                "last_cycle_time": data.get("generated_at"),
                "status": data.get("status", "unknown"),
                "issues": data.get("issues", []),
                "trades_24h": trades.get("trades_24h", 0),
                "log_active": log.get("log_active", False),
                "log_age_minutes": log.get("log_age_minutes"),
                "format": "t488"
            }
        else:
            return None
    except Exception as e:
        print(f"Warning: Could not load health status: {e}")
        return None


def load_trades_from_file(filepath, source_tag=None):
    """Load trades from a JSONL file, optionally tagging with source."""
    trades = []
    if not filepath.exists():
        return trades
    
    with open(filepath, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                trade = json.loads(line)
                if source_tag:
                    trade['_source'] = source_tag
                trades.append(trade)
            except json.JSONDecodeError:
                continue
    return trades

def load_trades(source='v2'):
    """Load trades based on source selection."""
    if source == 'v1':
        return load_trades_from_file(TRADES_FILE_V1, 'v1')
    elif source == 'v2':
        return load_trades_from_file(TRADES_FILE_V2, 'v2')
    elif source == 'all':
        v1_trades = load_trades_from_file(TRADES_FILE_V1, 'v1')
        v2_trades = load_trades_from_file(TRADES_FILE_V2, 'v2')
        # Combine and sort by timestamp
        combined = v1_trades + v2_trades
        combined.sort(key=lambda t: t.get('timestamp', ''))
        return combined
    else:
        return load_trades_from_file(TRADES_FILE_V2, 'v2')

def calculate_stats(trades, source='v2'):
    """Calculate trading statistics."""
    if not trades:
        return {
            "source": source,
            "totalTrades": 0,
            "winRate": 0,
            "pnlCents": 0,
            "todayTrades": 0,
            "todayWinRate": 0,
            "todayPnlCents": 0,
            "byAsset": {},
            "bySource": {} if source == 'all' else None,
            "lastUpdated": datetime.now(timezone.utc).isoformat()
        }
    
    # Filter settled trades
    settled = [t for t in trades if t.get('result_status') in ['won', 'lost']]
    
    # Calculate overall stats
    wins = sum(1 for t in settled if t.get('result_status') == 'won')
    total = len(settled)
    win_rate = (wins / total * 100) if total > 0 else 0
    
    # Calculate PnL
    total_pnl = 0
    gross_profit = 0
    gross_loss = 0
    
    for t in settled:
        price = t.get('price', 50)
        contracts = t.get('contracts', 1)
        won = t.get('result_status') == 'won'
        
        if won:
            profit = (100 - price) * contracts
            total_pnl += profit
            gross_profit += profit
        else:
            loss = price * contracts
            total_pnl -= loss
            gross_loss += loss
    
    # Today's stats
    today = datetime.now(timezone.utc).date().isoformat()
    today_trades = [t for t in settled if t.get('timestamp', '').startswith(today)]
    today_wins = sum(1 for t in today_trades if t.get('result_status') == 'won')
    today_total = len(today_trades)
    today_win_rate = (today_wins / today_total * 100) if today_total > 0 else 0
    
    today_pnl = 0
    for t in today_trades:
        price = t.get('price', 50)
        contracts = t.get('contracts', 1)
        if t.get('result_status') == 'won':
            today_pnl += (100 - price) * contracts
        else:
            today_pnl -= price * contracts
    
    # Latency stats
    latencies = [t.get('latency_ms') for t in trades if t.get('latency_ms') is not None]
    latency_stats = {}
    if latencies:
        latencies_sorted = sorted(latencies)
        n = len(latencies)
        latency_stats = {
            "avgLatencyMs": round(sum(latencies) / n),
            "p95LatencyMs": latencies_sorted[int(n * 0.95)] if n >= 20 else latencies_sorted[-1],
            "minLatencyMs": latencies_sorted[0],
            "maxLatencyMs": latencies_sorted[-1],
            "latencyTradeCount": n
        }
        
        # Compute daily latency trend (last 14 days)
        from collections import defaultdict
        by_day = defaultdict(list)
        for t in trades:
            if t.get('latency_ms') is None:
                continue
            ts = t.get('timestamp', '')
            if not ts:
                continue
            day_key = ts[:10]  # YYYY-MM-DD
            by_day[day_key].append(t['latency_ms'])
        
        latency_trend = []
        for day in sorted(by_day.keys())[-14:]:  # Last 14 days
            day_latencies = sorted(by_day[day])
            n_day = len(day_latencies)
            latency_trend.append({
                "timestamp": f"{day}T12:00:00Z",
                "avgMs": round(sum(day_latencies) / n_day),
                "p95Ms": day_latencies[int(n_day * 0.95)] if n_day >= 5 else day_latencies[-1],
                "minMs": day_latencies[0],
                "maxMs": day_latencies[-1],
                "count": n_day
            })
        latency_stats["trend"] = latency_trend
    
    # By asset breakdown
    by_asset = {}
    for asset in ['BTC', 'ETH']:
        asset_trades = [t for t in settled if t.get('asset', 'BTC') == asset]
        asset_wins = sum(1 for t in asset_trades if t.get('result_status') == 'won')
        asset_total = len(asset_trades)
        
        asset_pnl = 0
        for t in asset_trades:
            price = t.get('price', 50)
            contracts = t.get('contracts', 1)
            if t.get('result_status') == 'won':
                asset_pnl += (100 - price) * contracts
            else:
                asset_pnl -= price * contracts
        
        by_asset[asset] = {
            "trades": asset_total,
            "winRate": round(asset_wins / asset_total * 100, 1) if asset_total > 0 else 0,
            "pnlCents": asset_pnl
        }
    
    # Profit factor
    profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf') if gross_profit > 0 else 0
    
    # Max drawdown
    cumulative = 0
    peak = 0
    max_drawdown = 0
    
    for t in settled:
        price = t.get('price', 50)
        contracts = t.get('contracts', 1)
        if t.get('result_status') == 'won':
            cumulative += (100 - price) * contracts
        else:
            cumulative -= price * contracts
        
        if cumulative > peak:
            peak = cumulative
        drawdown = peak - cumulative
        if drawdown > max_drawdown:
            max_drawdown = drawdown
    
    max_dd_percent = (max_drawdown / peak * 100) if peak > 0 else 0
    
    # By source breakdown (only when source='all')
    by_source = None
    if source == 'all':
        by_source = {}
        for src in ['v1', 'v2']:
            src_trades = [t for t in settled if t.get('_source') == src]
            src_wins = sum(1 for t in src_trades if t.get('result_status') == 'won')
            src_total = len(src_trades)
            
            src_pnl = 0
            for t in src_trades:
                price = t.get('price', 50)
                contracts = t.get('contracts', 1)
                if t.get('result_status') == 'won':
                    src_pnl += (100 - price) * contracts
                else:
                    src_pnl -= price * contracts
            
            by_source[src] = {
                "trades": src_total,
                "winRate": round(src_wins / src_total * 100, 1) if src_total > 0 else 0,
                "pnlCents": src_pnl,
                "pnlDollars": round(src_pnl / 100, 2)
            }
    
    result = {
        "source": source,
        "totalTrades": total,
        "winRate": round(win_rate, 1),
        "pnlCents": total_pnl,
        "pnlDollars": round(total_pnl / 100, 2),
        "grossProfitCents": gross_profit,
        "grossLossCents": gross_loss,
        "profitFactor": round(profit_factor, 2) if profit_factor != float('inf') else "âˆž",
        "maxDrawdownCents": max_drawdown,
        "maxDrawdownPercent": round(max_dd_percent, 1),
        "todayTrades": today_total,
        "todayWinRate": round(today_win_rate, 1),
        "todayPnlCents": today_pnl,
        "byAsset": by_asset,
        "pendingTrades": len([t for t in trades if t.get('result_status') == 'pending']),
        **latency_stats,
        "lastUpdated": datetime.now(timezone.utc).isoformat()
    }
    
    if by_source:
        result["bySource"] = by_source
    
    # Add volatility stats
    vol_stats = load_volatility_stats()
    if vol_stats:
        result["volatility"] = vol_stats
    
    # Add autotrader health status (T620)
    health_status = load_health_status()
    if health_status:
        result["healthStatus"] = health_status
    
    # Add API latency stats (T398)
    api_latency = load_api_latency_stats()
    if api_latency:
        result["apiLatency"] = api_latency
    
    # Add settlement stats (T349)
    settlements = load_settlements_stats()
    if settlements:
        result["settlements"] = settlements
    
    return result

def get_gist_id():
    """Get existing gist ID or return None."""
    if GIST_ID_FILE.exists():
        return GIST_ID_FILE.read_text().strip()
    return None

def save_gist_id(gist_id):
    """Save gist ID for future updates."""
    GIST_ID_FILE.parent.mkdir(parents=True, exist_ok=True)
    GIST_ID_FILE.write_text(gist_id)

def create_gist(stats_json):
    """Create a new public gist."""
    # Write stats to temp file
    temp_file = Path("/tmp") / STATS_FILENAME
    temp_file.write_text(stats_json)
    
    # Create gist
    result = subprocess.run(
        ["gh", "gist", "create", str(temp_file), "--public", "--desc", "Onde Trading Stats (auto-updated)"],
        capture_output=True, text=True
    )
    
    if result.returncode != 0:
        print(f"Error creating gist: {result.stderr}")
        return None
    
    # Parse gist URL to get ID
    gist_url = result.stdout.strip()
    gist_id = gist_url.split("/")[-1]
    
    print(f"Created gist: {gist_url}")
    print(f"Raw URL: https://gist.githubusercontent.com/FreeRiverHouse/{gist_id}/raw/{STATS_FILENAME}")
    
    return gist_id

def update_gist(gist_id, stats_json):
    """Update existing gist using GitHub API."""
    # Build payload for gist API
    payload = {
        "files": {
            STATS_FILENAME: {
                "content": stats_json
            }
        }
    }
    
    # Update gist via gh api
    result = subprocess.run(
        ["gh", "api", "-X", "PATCH", f"/gists/{gist_id}", "-f", f"files[{STATS_FILENAME}][content]={stats_json}"],
        capture_output=True, text=True
    )
    
    if result.returncode != 0:
        print(f"Error updating gist: {result.stderr}")
        return False
    
    print(f"Updated gist: https://gist.github.com/{gist_id}")
    return True

def main():
    create_new = "--create" in sys.argv
    
    # Parse source argument
    source = 'v2'  # default
    for i, arg in enumerate(sys.argv):
        if arg == '--source' and i + 1 < len(sys.argv):
            source = sys.argv[i + 1]
            if source not in ['v1', 'v2', 'all']:
                print(f"Invalid source '{source}'. Use v1, v2, or all.")
                sys.exit(1)
    
    # Load trades and calculate stats
    trades = load_trades(source)
    stats = calculate_stats(trades, source)
    stats_json = json.dumps(stats, indent=2)
    
    source_label = f"[{source}] " if source != 'v2' else ""
    print(f"{source_label}Stats: {stats['totalTrades']} trades, {stats['winRate']}% win rate, ${stats.get('pnlDollars', 0)} PnL")
    
    # Show source breakdown when combined
    if source == 'all' and 'bySource' in stats:
        for src, src_stats in stats['bySource'].items():
            print(f"  {src}: {src_stats['trades']} trades, {src_stats['winRate']}% WR, ${src_stats['pnlDollars']} PnL")
    
    gist_id = get_gist_id()
    
    if create_new or not gist_id:
        print("Creating new gist...")
        gist_id = create_gist(stats_json)
        if gist_id:
            save_gist_id(gist_id)
            print(f"Saved gist ID to {GIST_ID_FILE}")
    else:
        print(f"Updating existing gist {gist_id}...")
        update_gist(gist_id, stats_json)
    
    # Print raw URL for static site
    if gist_id:
        raw_url = f"https://gist.githubusercontent.com/FreeRiverHouse/{gist_id}/raw/{STATS_FILENAME}"
        print(f"\nFetch URL for static site:\n{raw_url}")

if __name__ == "__main__":
    main()
